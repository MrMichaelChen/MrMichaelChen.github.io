---
layout:     post
title:      hive基本原理
subtitle:   Apache hive
date:       2018-07-24
author:     CDX
header-img: img/post-bg-hacker.jpg
catalog: true
tags:
    - Swift
---
## 写在前面  

Apache Hive是一个建立在Hadoop架构之上的数据仓库。它能够提供数据的精炼，查询和分析。  
Apache Hive起初由Facebook开发，目前也有其他公司使用和开发Apache Hive，例如Netflix等。亚马逊公司也开发了一个定制版本的Apache Hive，亚马逊网络服务包中的Amazon Elastic MapReduce包含了该定制版本。  

[hive](https://hive.apache.org/)是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的[SQL](https://zh.wikipedia.org/wiki/SQL "SQL")查询功能，可以将SQL语句转换为MapReduce任务进行运行。  
   
其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。

## hive基本原理

Hive通过给用户提供的一系列交互接口，接收到用户的指令(SQL)，使用自己的Driver，结合元数据(MetaStore)，将这些指令翻译成MapReduce，提交到Hadoop中执行，最后，将执行返回的结果输出到用户交互接口。
>HiveQL通过CLI、Web UI、thrift/

## 安装与使用

安装略，配置文件需要注意。  

**使用**  

1、hive的用户接口共有三个: CLI, JDBC/ODBC, 和 WebUI。
```
hive --service metastore &    //启用元数据表 
hive --service cli       //命令行模式，也可直接hive
hive --service hwi &            //web界面
hive --service hiveserver2 &   //启动hive远程服务，可以使用jdbc连接
```  

2、hive是一个数据仓库，本质上是一个sql解析引擎，hive会把insert、update等操作转化为MapReduce中的job来进行，但是select语句不会生成MapReduce任务。  

3、hive有一套映射工具，可以数据库中的表格转换为HDFS中的文件，以及文件中的列。  

4、元数据存放在Derby或者MySQL中，建议使用MySQL，可以更好地承受高并发的压力，元数据并不是真正的数据，只是数据的映射。元数据包括表的名字、表的列、分区分桶以及属性，表的属性，表的数据所在的目录等。  
```
数据单元:
    Databases:数据库，类似关系型数据库的Schema
    Tables:表
    Parttions:分区，相当于关系型数据库的表分区，只支持固定分区，将同  
    一组数据存放至一个固定的分区中，也就是hdfs中分目录存储。
    Buckets:分桶，同一个分区内的数据还能细分，将相同的key划分到一个  
    桶中，类似于hash分区或子分区。
```
5、解释器、编译器、优化器完成HQL查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在HDFS中，并在随后在MapReduce中调用执行。  

6、hive的数据默认存储位置为/user/hive/warehouse，配置文件hive-conf.xml中的属性`hive.metastore.warehouse.dir`可以修改此默认设置。  

注: hql是面向对象查询，格式：from + 类名 + 类对象 + where + 对象的属性
     sql是面向数据库表查询，格式：from + 表名 + where + 表中字段

## 元数据表
    -metastore是hive元数据的集中存放地，默认使用内嵌的derby数据库作为存储引擎。
    -derby引擎的缺点:一次只能打开一个会话。
    -使用MySQL作为外置存储引擎，可以同时响应多用户。

## hive基础命令
 [参考链接](https://www.yiibai.com/hive/hive_data_types.html)
```
mysql~
```












