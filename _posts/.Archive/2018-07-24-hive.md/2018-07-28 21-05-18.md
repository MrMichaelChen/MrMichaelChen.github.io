---
layout:     post
title:      hive基本原理
subtitle:   Apache hive
date:       2018-07-24
author:     CDX
header-img: img/post-bg-hacker.jpg
catalog: true
tags:
    - Swift
---
## 写在前面  

Apache Hive是一个建立在Hadoop架构之上的数据仓库。它能够提供数据的精炼，查询和分析。  
Apache Hive起初由Facebook开发，目前也有其他公司使用和开发Apache Hive，例如Netflix等。亚马逊公司也开发了一个定制版本的Apache Hive，亚马逊网络服务包中的Amazon Elastic MapReduce包含了该定制版本。  

[hive](https://hive.apache.org/)是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的[SQL](https://zh.wikipedia.org/wiki/SQL "SQL")查询功能，可以将SQL语句转换为MapReduce任务进行运行。  
   
其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。

## hive基本原理

Hive通过给用户提供的一系列交互接口，接收到用户的指令(SQL)，使用自己的Driver，结合元数据(MetaStore)，将这些指令翻译成MapReduce，提交到Hadoop中执行，最后，将执行返回的结果输出到用户交互接口。
>HiveQL通过CLI、Web UI、thrift/odbc/jdbc接口的外部提交，经过  
complier编译器，运用Metastore中的云数据进行类型检测和语法分析，生  
成一个逻辑方案(logical plan)，然后经过简单的优化处理，产生一个以有向  
无环图DAG数据结构形式展现的MapReduce任务。
>首先进行hql语句解析，构造一颗AST树，从AST树中得到QueryBlock，再  
将QB转为对应的操作符，生成逻辑查询计划，对逻辑查询计划进行优化(谓  
词下推)，生成物理查询计划，对物理查询计划进行优化(MapJoinResolver/  
SkewJoinResolver/CommonJoinResolver)，得到最后的执行计划。
  
>MapJoinResolver：将小表的MR结果放入HashTableFiles--  
DistributedCache,大表从分布式缓存中取得数据进行join；当hash数据较  
大时，分布式缓存查询效率降低，同时大表的Map都>在等待hash files；所  
以对其进行列优化处理小表的结果放到DC中进行压缩和更新，大表遍历时从  
DC中取出tar包>，然后解压读取本地的hash files

## 安装与使用

安装略，配置文件需要注意。  

**使用**  

1、hive的用户接口共有三个: CLI, JDBC/ODBC, 和 WebUI。
```
hive --service metastore &    //启用元数据表 
hive --service cli       //命令行模式，也可直接hive
hive --service hwi &            //web界面
hive --service hiveserver2 &   //启动hive远程服务，可以使用jdbc连接
```  

2、hive是一个数据仓库，本质上是一个sql解析引擎，hive会把insert、update等操作转化为MapReduce中的job来进行，但是select语句不会生成MapReduce任务。  

3、hive有一套映射工具，可以数据库中的表格转换为HDFS中的文件，以及文件中的列。  

4、元数据存放在Derby或者MySQL中，建议使用MySQL，可以更好地承受高并发的压力，元数据并不是真正的数据，只是数据的映射。元数据包括表的名字、表的列、分区分桶以及属性，表的属性，表的数据所在的目录等。  
```
数据单元:
    Databases:数据库，类似关系型数据库的Schema
    Tables:表
    Parttions:分区，相当于关系型数据库的表分区，只支持固定分区，将同  
    一组数据存放至一个固定的分区中，也就是hdfs中分目录存储。
    Buckets:分桶，同一个分区内的数据还能细分，将相同的key划分到一个  
    桶中，类似于hash分区或子分区。
```
5、解释器、编译器、优化器完成HQL查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在HDFS中，并在随后在MapReduce中调用执行。  

6、hive的数据默认存储位置为/user/hive/warehouse，配置文件hive-conf.xml中的属性`hive.metastore.warehouse.dir`可以修改此默认设置。  

注: hql是面向对象查询，格式：from + 类名 + 类对象 + where + 对象的属性
     sql是面向数据库表查询，格式：from + 表名 + where + 表中字段

## 元数据表
    -metastore是hive元数据的集中存放地，默认使用内嵌的derby数据库作为存储引擎。
    -derby引擎的缺点:一次只能打开一个会话。
    -使用MySQL作为外置存储引擎，可以同时响应多用户。

## hive基础命令
```
>   create external table student(name string,sex string) partitioned by(dept string) location '/test';    创建数据库
>   insert into table student partition (dept="cs") values("cdx","man");    hive向已有分区的数据表中插入数据
>   create index key_index on table cdx(key) as 'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler'with deferred rebuild;     建立索引
>
 ```
 [参考链接](https://www.yiibai.com/hive/hive_data_types.html)
```
mysql~
```












