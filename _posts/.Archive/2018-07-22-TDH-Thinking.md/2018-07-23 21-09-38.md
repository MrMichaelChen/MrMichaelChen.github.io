---
layout:     post
title:      面试准备
subtitle:   面试准备
date:       2018-07-22
author:     cdx
header-img: img/post-bg-hacker.jpg
catalog: true
tags:
    - Hadoop
---
引言:
让我用一个思维实验来展示一个 Android 用户在这个大数据生态链中的位置吧（当然任何一个读者都可以亲自尝试，用 iPhone 手机效果会大打折扣）。某个周末，你来到了某个商场，在一个咖啡厅里面点了一杯咖啡，然后开始用智能手机上网。咖啡厅提供了免费 Wi-Fi 网络，由于法规要求需要你提供手机号进行实名认证，你毫不犹豫地输入了手机号。于是免费 Wi-Fi 的服务商知道了你的信息：你的手机号和智能手机的 MAC。然后你开始刷微博，由于微博的 API 通常不使用加密信道，于是 Wi-Fi 热点通过偷窥 HTTP 请求获得了你的微博账号。通过你的微博，Wi-Fi 服务商有可能了解你的性别年龄工作等信息。此外通过该热点请求的很多元信息都会被服务商保留，虽然它们未必知道怎么挖掘这些元信息，但是它们会尽量将你的身份和这些信息关联在一起并长期保留。喝完咖啡，你开始逛街，这时候你的手机会开始扫描热点，商场可以通过 Wi-Fi 探针追踪你的位置。如果商场使用的 Wi-Fi 服务商和咖啡厅是同一家，或者与服务商建立了数据交换的协议，那么商场有可能实名地追踪你的轨迹。商场的 Wi-Fi 服务商同样会非常有耐心地存储你的信息，以备不时之需。在逛街的过程中，你打开了一些购物 App 用于比价，顺便拍了一些照片发给好友。其中一些 App 会把你的 MAC 地址和通过 Wi-Fi 完成的定位信息也发送出去。如果存在一个完备的数据交易网络，任何对你感兴趣的人都有可能获得以下信息：你的电话号码、手机的 MAC、微博账号，何时出现在这个商场，在商场停留了多久，其间使用了哪些 App，在咖啡厅访问了哪些网站。而这一切都离不开 Wi-Fi 和 MAC。如果更极端一点，你使用了专车软件来这个商场，并且你经常来这家商场，那么你很可能已经在商场的常客数据库里了，你的家庭住址也不再是个秘密。让我用一个思维实验来展示一个 Android 用户在这个大数据生态链中的位置吧（当然任何一个读者都可以亲自尝试，用 iPhone 手机效果会大打折扣）。某个周末，你来到了某个商场，在一个咖啡厅里面点了一杯咖啡，然后开始用智能手机上网。咖啡厅提供了免费 Wi-Fi 网络，由于法规要求需要你提供手机号进行实名认证，你毫不犹豫地输入了手机号。于是免费 Wi-Fi 的服务商知道了你的信息：你的手机号和智能手机的 MAC。然后你开始刷微博，由于微博的 API 通常不使用加密信道，于是 Wi-Fi 热点通过偷窥 HTTP 请求获得了你的微博账号。通过你的微博，Wi-Fi 服务商有可能了解你的性别年龄工作等信息。此外通过该热点请求的很多元信息都会被服务商保留，虽然它们未必知道怎么挖掘这些元信息，但是它们会尽量将你的身份和这些信息关联在一起并长期保留。喝完咖啡，你开始逛街，这时候你的手机会开始扫描热点，商场可以通过 Wi-Fi 探针追踪你的位置。如果商场使用的 Wi-Fi 服务商和咖啡厅是同一家，或者与服务商建立了数据交换的协议，那么商场有可能实名地追踪你的轨迹。商场的 Wi-Fi 服务商同样会非常有耐心地存储你的信息，以备不时之需。在逛街的过程中，你打开了一些购物 App 用于比价，顺便拍了一些照片发给好友。其中一些 App 会把你的 MAC 地址和通过 Wi-Fi 完成的定位信息也发送出去。如果存在一个完备的数据交易网络，任何对你感兴趣的人都有可能获得以下信息：你的电话号码、手机的 MAC、微博账号，何时出现在这个商场，在商场停留了多久，其间使用了哪些 App，在咖啡厅访问了哪些网站。而这一切都离不开 Wi-Fi 和 MAC。如果更极端一点，你使用了专车软件来这个商场，并且你经常来这家商场，那么你很可能已经在商场的常客数据库里了，你的家庭住址也不再是个秘密。<br>
这个思维实验当然是虚构的，因为利益冲突无关公司之间很难达成信任，它们很少进行实质性的数据交换。但是寡头们可以通过收购和战略投资将第三方变成第二方，甚至亲自介入 Wi-Fi 热点的服务。利用这些数据和技术，大数据公司事实上可以将营销做到无孔不入。例如，利用上述信息，商场中的餐厅可以针对最近到过商场的用户推送折扣信息，并且根据情况选择短信或微博作为送达渠道。当然现实社会中的餐厅并不会走得这么远，它们更倾向于使用微信服务号一类的技术来建立会员机制。各种 P2P 金融公司、讨债公司对数据更加饥渴，它们会愿意为你的信息（尤其是位置信息）付大价钱。所以从某种意义上说，数据寡头更可能看重你的隐私的长期价值。<br>

## 大数据个人认识
1、数据可视化
2、量化分析
3、Hadoop、NoSQL搜索引擎、批量分析组件、流处理组件和数据挖掘组件
## 源数据和数据集
1、数据集录入
2、数据报表
## TDH Inceptor
1、PL/SQL引擎
2、交互分析
3、图计算
## TDH Stream
1、流处理引擎
2、SQL
## 数据挖掘工具Discover
1、集成notebook
2、不同语言编程
3、不同用户同时广播
4、机器学习
## TDH Hyperbase
1、NoSQL数据库综合搜索
## TDH Midas
1、神经网络编程
2、资源库和算子
3、从设计到结果
## 资源管理 YARN
• 用户将应用程序提交到RM 
• RM为AM申请资源，与某个NM通信，启动AM 
• AM与RM通信，为执行任务申请资源 
• 得到资源后与NM通信，启动相应的任务
• 所有任务结束后，AM向RM注销，整个应用结束
## 优化存储HDFS、全文搜索
## MR
• 一个split（切片）起一个map任务 • map输出时会先将输出中间结果写入到buffer中 
• 在buffer中对数据进行partition（分区，partition数为reduce数）和基于key的 sort（排序），达到阈值后spill到本地磁盘 
• 在map任务结束之前，会对输出的多个文件进行merge（合并），合并成一个 文件 • 每个reduce任务会从多个map输出中拷贝自己的partition 
• reduce也会将数据先放到buffer中，达到阈值会写到磁盘 
• 当数据该reduce的map输出全部拷贝完成，合并多个文件成一个文件，并保持 基于key的有序 
• 最后，执行reduce阶段，运行我们实现的reduce中化简逻辑，最终将结果直接 输出到HDFS中