---
layout:     post
title:      hbase基本原理
subtitle:   Hadoop Database
date:       2018-7-24
author:     cdx
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - iOS
    - 开发技巧
---
## 写在前面
HBase，就是Hadoop Database，Google BigTable的另一种开源实现方式。从问世之初，就为了解决用大量廉价的机器高速存取海量数据、实现数据分布式存储提供可靠的方案。  
从功能上来讲，HBase不折不扣是一个数据库，与我们熟悉的Oracle、MySQL、MSSQL等一样，对外提供数据的存储和读取服务。  
而从应用的角度来说，HBase与一般的数据库又有所区别，HBase本身的存取接口相当简单，不支持复杂的数据存取，更不支持SQL等结构化的查询语言；HBase也没有除了rowkey以外的索引，所有的数据分布和查询都依赖rowkey。
  
## 基本原理
  
从功能上可划分为Zookeeper、Master、RegionServer。
  
Zookeeper:调度，中间通信。
  
Master:管理，资源分配，命令下发。
  
RegionServer:存储数据，每一个RegionServer有多个region组成，每个region维护了一定区间的rowkey的数据。
```
获得RS地址:
    1、首先，Client通过访问Zookeeper请求目的数据的地址
    2、Zookeeper中保存了-ROOT-表的地址，所以Zookeeper通过访问-ROOT-表来请求数据地址
    3、-ROOT-表中保存的是.META.的信息，通过访问.META.表来获取具体的RS 
    4、.META.表查询到具体的RS信息后返回具体的RS地址给client
    5、client端获取RS目标地址后，直接向该地址发送数据请求。
    从ZK获取-ROOT-信息，再从-ROOT-获取.META.表信息，最后从.META.表中查到RS地址后缓存。
```
```
Region数据写入:
    1、获得RS地址
    2、数据写入，WAL方式，先写log，再写数据。HBase是一个append类型的数据库，没有关系型数据库那么复杂  
    的操作，所以记录HLog非常简单，即put操作。
    3、HLog写入，每个Rs上的region共享一个HLog，所以对于该RS上的region数据写入都被记录到该HLog中。  
    HLog的作用就是在RS出现意外崩溃的时候，可以尽量多的恢复数据。
    4、HLog过期，当数据从memstore flush到底层存储上后，说明该段的HLog已经不再需要，就会被移动  
    到.oldlogs的目录下，HLog监控线程实时监控该目录，达到配置项hbase.master.logcleaner.ttl中设置的过期条件  
    之后，监控线程立即删除过期的HLog。
    5、数据存储，memstore是region的内部缓存，其大小通过HBase参数hbase.hregion.memstore.flush.size进行  
    配置。memstore在HBase内部通过LSM-tree结构组织，能够合并大量对于相同rowkey上的更新操作。(正是由于  
    memstore的存在，HBase的数据写入都是异步的，而且性能非常不错，写入到memstore后，该次写入请求就可以  
    被返 回，HBase即认为该次数据写入成功。这里有一点需要说明，写入到memstore中的数据都是预先按照rowkey  
    的值进行排序的，这样有利于后续数 据查找。)
    6、数据刷盘，Memstore中的数据在一定条件下会进行刷写操作，使数据持久化到相应的存储设备上。
    StoreFile-->Compact-->Split
```
## 基本命令
```
create 表名称，列名称1，列名称2，列名称3
put 表名称，行名称，列名称，值
get 表名称，行名称
count 表名称
delete 表名，行名，列名
disable 表名
drop 表名
scan 表名
scan 表名 列名
```
[HBase基础命令](https://www.yiibai.com/hbase/hbase_general_commands.html)
## odbc
```
package hadoop_pro;

import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.HColumnDescriptor;
import org.apache.hadoop.hbase.HTableDescriptor;
import org.apache.hadoop.hbase.KeyValue;
import org.apache.hadoop.hbase.MasterNotRunningException;
import org.apache.hadoop.hbase.ZooKeeperConnectionException;
import org.apache.hadoop.hbase.client.Delete;
import org.apache.hadoop.hbase.client.Durability;
import org.apache.hadoop.hbase.client.Get;
import org.apache.hadoop.hbase.client.HBaseAdmin;
import org.apache.hadoop.hbase.client.HTable;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.client.ResultScanner;
import org.apache.hadoop.hbase.client.Scan;
import org.apache.hadoop.hbase.thrift.generated.Hbase.AsyncProcessor.createTable;
import org.apache.hadoop.hbase.util.Bytes;
import org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.sysFuncNames_return;
import org.apache.log4j.Logger;

import com.sun.org.apache.xalan.internal.xsltc.compiler.sym;

public class HbaseDao {
	public static Logger log = Logger.getLogger(HbaseDao.class);
	public static Configuration configuration;
	static {
		configuration = HBaseConfiguration.create();
		configuration.set("hbase.zookeeper.quorum", "192.168.1.51");
		//configuration.set("hbase_zookeeper_quorum", "ZooKeeper1,ZooKeeper2");
		configuration.set("hbase.zookeeper.property.clientPort","2181");
		configuration.set("hbase.master", "192.168.1.51:6000");
	}
	public static void main(String[] args) throws IOException {
		System.out.println("Finish！");
	}
	//创建表格
	public static void createTable(String tableName) throws IOException {
		// TODO Auto-generated method stub
		log.info("start create table .....");
		try {
			HBaseAdmin hBaseadmin = new HBaseAdmin(configuration);
			if (hBaseadmin.tableExists(tableName)) {
				// 如果存在数据库 先删除在创建 爱晨
				hBaseadmin.disableTable(tableName);
				hBaseadmin.deleteTable(tableName);
				log.info("------------->"+tableName+" is exist,delete....");
			}
			HTableDescriptor tableDescriptor = new HTableDescriptor(tableName);
			// 添加数据family
			tableDescriptor.addFamily(new HColumnDescriptor("column1"));
			tableDescriptor.addFamily(new HColumnDescriptor("column2"));
			tableDescriptor.addFamily(new HColumnDescriptor("column3"));
			hBaseadmin.createTable(tableDescriptor);
		}catch(MasterNotRunningException e) {
			e.printStackTrace();
		}catch (ZooKeeperConnectionException e) {
			e.printStackTrace();
		}catch (IOException e) {
			e.printStackTrace();
		}
	}
	//插入数据 变量后期定义
	public static void insertData(String rowkey, String tableName,String columnname,String familyname,String keyvalue) {
		try {
			HTable ht = new HTable(configuration,tableName);
			//row key 
			Put put = new Put(rowkey.getBytes());
			put.add(Bytes.toBytes(columnname),familyname.getBytes(),keyvalue.getBytes());
			put.setDurability(Durability.SYNC_WAL);
			ht.put(put);
			ht.close();
		}catch (IOException e) {
			e.printStackTrace();
		}
	}
	// 删除数据表格
	public static void dropTable(String tableName) {
		try {
			HBaseAdmin admin = new HBaseAdmin(configuration);
			admin.disableTable(tableName);
			admin.deleteTable(tableName);
			log.info("------------->"+tableName+"is exist,delete....");
		}catch(MasterNotRunningException e){
			e.printStackTrace();
		}catch(ZooKeeperConnectionException e) {
			e.printStackTrace();
		}catch(IOException e) {
			e.printStackTrace();
		}
	}
	//删除表中的一条记录
	public static void deleteRow(String tablename,String rowkey) {
		// TODO Auto-generated method stub
		try {
			HTable table = new HTable(configuration,tablename);
			List list = new ArrayList();
			Delete d1 = new  Delete(rowkey.getBytes());
			list.add(d1);
			table.delete(list);
			System.out.println("--------->"+rowkey+"删除成功");			
		}catch(IOException e){
			e.printStackTrace();
		}
	}
	//查询所有数据
	public static ResultScanner QueryAll(String tableName) {
		try {
			HTable table = new HTable(configuration,tableName);
			ResultScanner rs = table.getScanner(new Scan());
//			for (Result r : rs) {
//				System.out.println("获得到rowkey:"+new String(r.getRow()));
//				for (KeyValue keyValue : r.raw()) {
//					// System.out.println(new String(keyValue.getFamily()));
//					System.out.println("列"+new String(keyValue.getRow())+"   Family Name:"+new String(keyValue.getQualifier())+"====值："+new String(keyValue.getValue()));
//				}
//			}
			return rs;
		}catch (IOException e) {
			e.printStackTrace();
		}
		return null;
	}
	//单条件查询 根据rowkey查询值
	public static void QueryByCondition1(String rowkey,String tableName) {
		try {
			HTable table = new HTable(configuration,tableName);
			Get scan = new Get(rowkey.getBytes());
			Result r = table.get(scan);
			System.out.println("获得rowkey："+ new String(r.getRow()));
			for (KeyValue keyvalue:r.raw()) {
				System.out.println("列:"+ new String(keyvalue.getFamily()) + "值:" + new String(keyvalue.getValue()));
			}
		}catch (IOException e) {
			e.printStackTrace();
		}
	}
}
```




